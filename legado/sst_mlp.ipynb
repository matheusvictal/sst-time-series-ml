{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.basemap import shiftgrid\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNetwork():\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(nn.Module, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 32),\n",
    "            F.relu(),\n",
    "            nn.Linear(32, 32),\n",
    "            F.relu(),\n",
    "            nn.Linear(32, 16),\n",
    "            F.relu(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function: Mean Squared Error\n",
    "lossfunc = nn.MSELoss()\n",
    "\n",
    "# SGD = Stochastic Gradient Descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_evaluate(model, epochs, loss_function, optimizer, X_train, y_train, X_test, verbose=True):\n",
    "    # A variavel history_train e utilizada para armazenar a perda em cada epoca\n",
    "    history_train = np.zeros(epochs)\n",
    "\n",
    "    # colocar no modelo no tipo treino\n",
    "    model.train()\n",
    "\n",
    "    # o modelo sera treinado utilizando um batch, portanto, ha apenas um \n",
    "    # la√ßo para iterar as epocas no procedimento de teste \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model.forward(X_train)\n",
    "\n",
    "        # funcao perda\n",
    "        loss = loss_function(y_pred, y_train)\n",
    "\n",
    "        # o modo verboso imprime a informacao de treinamento\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch + 1}|{epochs}] Loss: {loss.item()}\")\n",
    "\n",
    "        # inclui a perda da epoca atual no history_train\n",
    "        history_train[epoch] = loss.item()\n",
    "\n",
    "        # limpa o gradiente\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # atualiza os parametros\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # coloca o modelo em modo de validacao\n",
    "    model.eval()\n",
    "\n",
    "    # desativa o caluclo do gradiente. isso e util para procedimentos inferenciais.\n",
    "    # doc.: (https://pytorch.org/docs/stable/generated/torch.no_grad.html)\n",
    "    with torch.no_grad():\n",
    "        # realiza predicoes para os conjuntos de treino e de teste\n",
    "        y_pred_train = model.forward(X_train)\n",
    "        y_pred_test = model.forward(X_test)\n",
    "\n",
    "    return history_train, y_pred_train, y_pred_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
