{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expansao de testes\n",
    "Esse notebook tem como objetivo:\n",
    "- gerar uma lista de pontos (séries sst) a serem analisados pelos benchmarks e SVR\n",
    "- comparar os resultados com estatísticas das séries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.basemap import shiftgrid\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from netuno import SSTHelper, SubserieDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '../dados/sst.mnmean.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SSTHelper.load_dataset(fp)\n",
    "df = SSTHelper.load_dataframe(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = '2021-12-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geracao de Pontos\n",
    "### Checagem\n",
    "Precisamos chegar se um ponto aleatório gerado é válido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid(df, lat, lon):\n",
    "    ts = SSTHelper.get_sst_series(df, lat, lon).sst.to_list()\n",
    "    if len(ts) == 0 or pd.isna(ts[0]):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_valid(df, 0, -72) # o valor retornado deve ser falso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_valid(df, -22, -72) # o valor retornado deve ser verdadeiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_even():\n",
    "    return randint(-90, 90) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geraçao de pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_points = set()\n",
    "list_not_points = set()\n",
    "n_points = 0\n",
    "\n",
    "while n_points < 100:\n",
    "    lat = generate_even() \n",
    "    lon = generate_even()\n",
    "    while (lat, lon) in list_not_points or (lat, lon) in list_points or not check_valid(df, lat, lon):\n",
    "        list_not_points.add((lat, lon))\n",
    "        lat = generate_even()\n",
    "        lon = generate_even()\n",
    "    list_points.add((lat, lon))\n",
    "    n_points += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_count = 0\n",
    "for point in list_points:\n",
    "    if not check_valid(df, point[0], point[1]):\n",
    "        invalid_count += 1\n",
    "\n",
    "invalid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_points = list(list_points)\n",
    "check_valid(df, list_points[0][0], list_points[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df = pd.DataFrame(list_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df.rename({0: 'lat', 1: 'lon'}, axis=1).to_csv('../dados/pontos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-50</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-66</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-68</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-64</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-12</td>\n",
       "      <td>-90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-2</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>34</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  -50   84\n",
       "1   30  174\n",
       "2   88    8\n",
       "3  -66   32\n",
       "4  -68  -20\n",
       "..  ..  ...\n",
       "95 -64   46\n",
       "96 -12  -90\n",
       "97  -2  158\n",
       "98  34  172\n",
       "99  12   50\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reler os pontos salvos em csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_points(filename):\n",
    "    list_points = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line_split = line.split(',')\n",
    "            try:\n",
    "                list_points.append((int(line_split[1]), int(line_split[2])))\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return list_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(filename):\n",
    "    list_rmse = []\n",
    "    list_mape = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line_split = line.split(',')\n",
    "            try:\n",
    "                list_rmse.append(float(line_split[1]))\n",
    "                list_mape.append(float(line_split[2]))\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return [list_rmse, list_mape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_points = read_list_points('../dados/pontos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_valid(df, list_points[35][0], list_points[35][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos pontos recolhidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Média das métricas de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_list = {\n",
    "    'Approximate Entropy': list_approximate_entropy,\n",
    "    'Benford Correlation': list_benford_correlation,\n",
    "    'Bin Entropy': list_bin_entropy,\n",
    "    'Standard Dev': list_std_deviation\n",
    "}\n",
    "\n",
    "error_metrics = {\n",
    "    'RMSE': 0, \n",
    "    'MAPE': 1\n",
    "}\n",
    "\n",
    "method_list = {\n",
    "    # 'SARIMA': sarima_results\n",
    "    'SVR': svr_results,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8182888545611833,\n",
       " 1.267544047783792,\n",
       " 0.8871647066079104,\n",
       " 0.06814168190305141,\n",
       " 0.8756034207514847]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_results = read_results('../dados/svr_results.csv')\n",
    "# sarima_results = read_results('../dados/sarima_results.csv')\n",
    "svr_results[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado da média das métricas de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======SVR======\n",
      "Mean RMSE: 0.6264165226863616\n",
      "Mean MAPE: 0.11248874207240384\n"
     ]
    }
   ],
   "source": [
    "for method in method_list:\n",
    "    print(f\"======{method}======\")\n",
    "    for metric in error_metrics:\n",
    "        print(f\"Mean {metric}: {np.mean(method_list[method][error_metrics[metric]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos pontos utilizando características selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar a biblioteca tsfresh para calcular estatísticas dos pontos recolhidos.\n",
    "As seguintes características serao consideradas:\n",
    "- Entropia aproximada\n",
    "- Dickey Fuller\n",
    "- Correlacao de Benford\n",
    "- Entropia em Bins\n",
    "- Desvio Padrao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:08<01:00,  1.44it/s]"
     ]
    }
   ],
   "source": [
    "list_approximate_entropy = []\n",
    "list_dickey_fuller = []\n",
    "list_benford_correlation = []\n",
    "list_bin_entropy = []\n",
    "list_std_deviation = []\n",
    "\n",
    "for point in tqdm(list_points):\n",
    "    ts = SSTHelper.get_sst_series(df, point[0], point[1]).sst.to_numpy()\n",
    "    list_approximate_entropy.append(feature_calculators.approximate_entropy(ts, 2, 3))\n",
    "    # list_dickey_fuller.append(feature_calculators.augmented_dickey_fuller())\n",
    "    list_benford_correlation.append(feature_calculators.benford_correlation(ts))\n",
    "    list_bin_entropy.append(feature_calculators.binned_entropy(ts, 12))\n",
    "    list_std_deviation.append(feature_calculators.standard_deviation(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.014112886818138763,\n",
       " 0.007971934298443388,\n",
       " 0.004236244276716089,\n",
       " 0.03719259914990307,\n",
       " 0.06872644348650409,\n",
       " 0.015578635029948745,\n",
       " 0.0047509081025102606,\n",
       " 0.013123363974808677,\n",
       " 0.020952415837208506,\n",
       " 0.011424320266474497,\n",
       " 0.017714929485714258,\n",
       " 0.014393590676349662,\n",
       " 0.01838124380095172,\n",
       " 0.04295707690097658,\n",
       " 0.01852886327637708,\n",
       " 0.09445157887627406,\n",
       " 0.016972597365026848,\n",
       " 0.019574497065578553,\n",
       " 0.015201681686188698,\n",
       " 0.009777450135520917,\n",
       " 0.016869349716802727,\n",
       " 0.04540094027663073,\n",
       " 0.017443151890342477,\n",
       " 0.009463622047693472,\n",
       " 0.010726673038203065,\n",
       " 0.021806650283604623,\n",
       " 0.02554624065924163,\n",
       " 0.09646643762626203,\n",
       " 0.0909790032397697,\n",
       " 0.01602414486354352,\n",
       " 0.019179399464398852,\n",
       " 0.018094423229008165,\n",
       " 0.01073091571700532,\n",
       " 0.016617262719807263,\n",
       " 0.01845313497855955,\n",
       " 0.01214350832072171,\n",
       " 0.010701043695981821,\n",
       " 0.01830239783034284,\n",
       " 0.01297894487946804,\n",
       " 0.01576099401654403,\n",
       " 0.014232375914220823,\n",
       " 0.014428411665719815,\n",
       " 0.10790594363450373,\n",
       " 0.010595941282528023,\n",
       " 0.015595397429197973,\n",
       " 0.010708645054205223,\n",
       " 0.008473983152373188,\n",
       " 0.009089664443050243,\n",
       " 0.011179622237350525,\n",
       " 0.015992877462885295,\n",
       " 0.012580236210426188,\n",
       " 0.0031951626222691083,\n",
       " 0.0,\n",
       " 0.013213858355505169,\n",
       " 0.016355352582180765,\n",
       " 0.020872088516777784,\n",
       " 0.011136438577380125,\n",
       " 0.013867511087944567,\n",
       " 0.015488385552537821,\n",
       " 0.012084869271988794,\n",
       " 0.008437596297287384,\n",
       " 0.01648708355452356,\n",
       " 0.018133618200312007,\n",
       " 0.017032492699964083,\n",
       " 0.010874714807140588,\n",
       " 0.019805985470844757,\n",
       " 0.021884655904358903,\n",
       " 0.01863910056293764,\n",
       " 0.01777795459884471,\n",
       " 0.011371605956277023,\n",
       " 0.020222696340552446,\n",
       " 0.006249452348517148,\n",
       " 0.014533213043705778,\n",
       " 0.023609841262964074,\n",
       " 0.01700346918456267,\n",
       " 0.006316093672035155,\n",
       " 0.02100414797633811,\n",
       " 0.052064462788182206,\n",
       " 0.011884377342846981,\n",
       " 0.012323232180765482,\n",
       " 0.013814205832061957,\n",
       " 0.012494347893895776,\n",
       " 0.02070208281510335,\n",
       " 0.011074731793084179,\n",
       " 0.018540455135642918,\n",
       " 0.01720567845408779,\n",
       " 0.009187573248900203,\n",
       " 0.011916313025281525,\n",
       " 0.015383659118911805,\n",
       " 0.011202494956410871,\n",
       " 0.10489713706518378,\n",
       " 0.0,\n",
       " 0.010483475420959478,\n",
       " 0.008473983152373188,\n",
       " 0.0132243500221806,\n",
       " 0.016415866983433232,\n",
       " 0.011668507371277573,\n",
       " 0.02608086380203138,\n",
       " 0.009183340515917713,\n",
       " 0.019535605544215753]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_approximate_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado de Correlaçao de Pearson com características selecionadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======SVR======\n",
      "Approximate Entropy\n",
      "(VS RMSE) Obtained -0.010 with p-value 0.918\n",
      "(VS MAPE) Obtained 0.040 with p-value 0.693\n",
      "Benford Correlation\n",
      "(VS RMSE) Obtained -0.038 with p-value 0.704\n",
      "(VS MAPE) Obtained 0.087 with p-value 0.392\n",
      "Bin Entropy\n",
      "(VS RMSE) Obtained -0.037 with p-value 0.713\n",
      "(VS MAPE) Obtained -0.250 with p-value 0.012\n",
      "Standard Dev\n",
      "(VS RMSE) Obtained -0.081 with p-value 0.422\n",
      "(VS MAPE) Obtained -0.130 with p-value 0.197\n"
     ]
    }
   ],
   "source": [
    "for method in method_list:\n",
    "    print(f\"======{method}======\")\n",
    "    for measure in measure_list:\n",
    "        print(measure)\n",
    "        for metric in error_metrics:\n",
    "            pearson, pvalue = pearsonr(method_list[method][error_metrics[metric]], measure_list[measure])\n",
    "            print(f\"(VS {metric}) Obtained {pearson:.3f} with p-value {pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos pontos utilizando tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_settings = ComprehensiveFCParameters()\n",
    "list_features = []\n",
    "\n",
    "for point in list_points:\n",
    "    ts = pd.DataFrame(SSTHelper.get_sst_series(df, point[0], point[1]).sst)\n",
    "    ts['id'] = 1\n",
    "    X = extract_features(ts, \n",
    "                        column_id='id',\n",
    "                        default_fc_parameters=extraction_settings,\n",
    "                        # we impute = remove all NaN features automatically\n",
    "                        impute_function=impute, disable_progressbar=True)\n",
    "    list_features.append(X.to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(list_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_features = np.array(list_features).T\n",
    "assert len(list_features) == n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_correlations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitor/Documents/sst-time-series-ml/venv/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "for metric in error_metrics:\n",
    "    metric_correlations = []\n",
    "    metric_error_list = svr_results[error_metrics[metric]]\n",
    "    for features in list_features:\n",
    "        corr = pearsonr(features, metric_error_list)\n",
    "        metric_correlations.append(corr)\n",
    "    dict_correlations[metric] = metric_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlations = pd.DataFrame(dict_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sst__variance_larger_than_standard_deviation</th>\n",
       "      <td>(0.44731979994315746, 3.0729881762891283e-06)</td>\n",
       "      <td>(-0.0702630374779277, 0.48727103505926067)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__has_duplicate_max</th>\n",
       "      <td>(-0.2237266202878018, 0.02524832714243999)</td>\n",
       "      <td>(-0.05919774523078725, 0.5585152661851898)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__has_duplicate_min</th>\n",
       "      <td>(-0.19308001819786774, 0.05426972831146174)</td>\n",
       "      <td>(0.4686162851521978, 8.78286928239777e-07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__has_duplicate</th>\n",
       "      <td>(-0.06041214486123031, 0.5504593942983133)</td>\n",
       "      <td>(0.24586401758492657, 0.013674486852831232)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__sum_values</th>\n",
       "      <td>(0.26743164161825345, 0.007147912651909794)</td>\n",
       "      <td>(-0.3890989849187379, 6.30946593973488e-05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <td>(0.3672714587770922, 0.00017073852592701697)</td>\n",
       "      <td>(-0.21833931785632546, 0.029084073610760968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <td>(0.36822982942794863, 0.00016367568314930861)</td>\n",
       "      <td>(-0.22058485581835238, 0.027429100806286678)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <td>(0.36645049694987414, 0.00017701204284872207)</td>\n",
       "      <td>(-0.22170067461413456, 0.026636938860558085)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "      <td>(0.36608678246247706, 0.0001798590710275413)</td>\n",
       "      <td>(-0.37528262646525656, 0.0001194512005474263)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             RMSE  \\\n",
       "sst__variance_larger_than_standard_deviation        (0.44731979994315746, 3.0729881762891283e-06)   \n",
       "sst__has_duplicate_max                                 (-0.2237266202878018, 0.02524832714243999)   \n",
       "sst__has_duplicate_min                                (-0.19308001819786774, 0.05426972831146174)   \n",
       "sst__has_duplicate                                     (-0.06041214486123031, 0.5504593942983133)   \n",
       "sst__sum_values                                       (0.26743164161825345, 0.007147912651909794)   \n",
       "...                                                                                           ...   \n",
       "sst__permutation_entropy__dimension_5__tau_1         (0.3672714587770922, 0.00017073852592701697)   \n",
       "sst__permutation_entropy__dimension_6__tau_1        (0.36822982942794863, 0.00016367568314930861)   \n",
       "sst__permutation_entropy__dimension_7__tau_1        (0.36645049694987414, 0.00017701204284872207)   \n",
       "sst__query_similarity_count__query_None__thresh...                                     (nan, nan)   \n",
       "sst__mean_n_absolute_max__number_of_maxima_7         (0.36608678246247706, 0.0001798590710275413)   \n",
       "\n",
       "                                                                                             MAPE  \n",
       "sst__variance_larger_than_standard_deviation           (-0.0702630374779277, 0.48727103505926067)  \n",
       "sst__has_duplicate_max                                 (-0.05919774523078725, 0.5585152661851898)  \n",
       "sst__has_duplicate_min                                 (0.4686162851521978, 8.78286928239777e-07)  \n",
       "sst__has_duplicate                                    (0.24586401758492657, 0.013674486852831232)  \n",
       "sst__sum_values                                       (-0.3890989849187379, 6.30946593973488e-05)  \n",
       "...                                                                                           ...  \n",
       "sst__permutation_entropy__dimension_5__tau_1         (-0.21833931785632546, 0.029084073610760968)  \n",
       "sst__permutation_entropy__dimension_6__tau_1         (-0.22058485581835238, 0.027429100806286678)  \n",
       "sst__permutation_entropy__dimension_7__tau_1         (-0.22170067461413456, 0.026636938860558085)  \n",
       "sst__query_similarity_count__query_None__thresh...                                     (nan, nan)  \n",
       "sst__mean_n_absolute_max__number_of_maxima_7        (-0.37528262646525656, 0.0001194512005474263)  \n",
       "\n",
       "[788 rows x 2 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correlations.index = feature_names\n",
    "df_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_correlations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vitor/Documents/sst-time-series-ml/source/5_expansao_testes.ipynb Cell 48\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vitor/Documents/sst-time-series-ml/source/5_expansao_testes.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_correlations\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMAPE\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_correlations' is not defined"
     ]
    }
   ],
   "source": [
    "df_correlations.sort_values(by='MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
