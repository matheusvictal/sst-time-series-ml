{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.basemap import shiftgrid\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataset = dataset.fillna(method='ffill')\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "dataset['Close'] = scaler.fit_transform(dataset['Close'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_data(ts, lookback, test_start):\n",
    "    data_raw = ts.to_numpy() # convercao da série para numpy\n",
    "    data = []\n",
    "    # laço para criar todas as combinacoes possiveis de comprimento igual a 'lookback'\n",
    "    for index in range(len(data_raw) - lookback):\n",
    "        # cada observaca 't' ira conter o pontos anteriores de 'lookbak'\n",
    "        data.append(data_raw[index: index + lookback])\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    # vetores para redes recorrentes possuem tres dimensoes:\n",
    "    # - numero de amostras (para treino e teste)\n",
    "    # - numero de passos no tempo (deinido pelo parametro 'lookback')\n",
    "    # - numero de variaveis (1 para o caso de serie univariada)\n",
    "\n",
    "    # o x e o y irao ter um deslocamento entre si de forma que cada ponto de\n",
    "    # 0 ate t-1 sera utilizado para prever o ponto t\n",
    "    x_train = data[:test_start, :-1, :]\n",
    "    y_train = data[:test_start, -1, :]\n",
    "\n",
    "    x_test = data[test_start:, :-1, :]\n",
    "    y_test = data[test_start:, -1, :]\n",
    "\n",
    "    # conversao para tensores pytorch\n",
    "    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "    y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "    y_test = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_base(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_layers, output_dim):\n",
    "        super(LSTM_base, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_base(input_dim=1, hidden_size=64, num_layers=1, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_evaluate(model, epochs, loss_function, optimizer, X_train, y_train, X_test, verbose=True):\n",
    "    # A variavel history_train e utilizada para armazenar a perda em cada epoca\n",
    "    history_train = np.zeros(epochs)\n",
    "\n",
    "    # colocar no modelo no tipo treino\n",
    "    model.train()\n",
    "\n",
    "    # o modelo sera treinado utilizando um batch, portanto, ha apenas um \n",
    "    # laço para iterar as epocas no procedimento de teste \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model.forward(X_train)\n",
    "\n",
    "        # funcao perda\n",
    "        loss = loss_function(y_pred, y_train)\n",
    "\n",
    "        # o modo verboso imprime a informacao de treinamento\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch + 1}|{epochs}] Loss: {loss.item()}\")\n",
    "\n",
    "        # inclui a perda da epoca atual no history_train\n",
    "        history_train[epoch] = loss.item()\n",
    "\n",
    "        # limpa o gradiente\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # atualiza os parametros\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # coloca o modelo em modo de validacao\n",
    "    model.eval()\n",
    "\n",
    "    # desativa o caluclo do gradiente. isso e util para procedimentos inferenciais.\n",
    "    # doc.: (https://pytorch.org/docs/stable/generated/torch.no_grad.html)\n",
    "    with torch.no_grad():\n",
    "        # realiza predicoes para os conjuntos de treino e de teste\n",
    "        y_pred_train = model.forward(X_train)\n",
    "        y_pred_test = model.forward(X_test)\n",
    "\n",
    "    return history_train, y_pred_train, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = create_split_data(ts=dataset, lookback=30, test_start=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_base(input_dim=1, hidden_size=32, num_layers=1, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao perda: MSE Loss\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# otimizadorAdam com lr=.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_train, y_pred_train, y_pred_test = training_and_evaluate(model=model,\n",
    "                                                                 epochs=50,\n",
    "                                                                 loss_function=loss_function,\n",
    "                                                                 optimizer=optimizer,\n",
    "                                                                 X_train=X_train,\n",
    "                                                                 y_train=y_train,\n",
    "                                                                 X_test=X_test,\n",
    "                                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(y_train, y_hat_train, y_test, y_hat_test):\n",
    "    \n",
    "    # aplica a transformacao inversa nos dados normalizados\n",
    "    y_train_rev = scaler.inverse_transform(y_train.detach().numpy()).tolist()\n",
    "    y_hat_train_rev = scaler.inverse_transform(y_hat_train.detach().numpy()).tolist()\n",
    "    y_test_rev = scaler.inverse_transform(y_test.detach().numpy()).tolist()\n",
    "    y_hat_test_rev = scaler.inverse_transform(y_hat_test.detach().numpy()).tolist()\n",
    "\n",
    "    # calcula e obtem o RMSE\n",
    "    train_RMSE = math.sqrt(mean_squared_error(y_train_rev, y_hat_train_rev))\n",
    "    test_RMSE = math.sqrt(mean_squared_error(y_test_rev, y_hat_test_rev))\n",
    "\n",
    "    print('Train score: {result} RMSE'.format(result=train_RMSE))\n",
    "    print('Test score: {result} RMSE'.format(result=test_RMSE))\n",
    "\n",
    "    # Imprime as previsoes para o conjunto de teste e os valores reais\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    df_lines = pd.DataFrame({'Actual Price': [value for sublist in y_test_rev for value in sublist],\n",
    "                             'Predicted Price': [value for sublist in y_hat_test_rev for value in sublist]})\n",
    "    sns.lineplot(data=df_lines,\n",
    "                 palette={'Actual Price': 'indigo', 'Predicted Price': 'deeppink'},\n",
    "                 linewidth=1.5)\n",
    "\n",
    "    plt.title('Stock Price Prediction', fontsize=16)\n",
    "    plt.xlabel('Time indicator (test set)', fontsize=12)\n",
    "    plt.ylabel('Stock Price', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(figsize=(10, 4))\n",
    "plt.plot(history_train, color = 'indigo')\n",
    "plt.title('Loss by trainning epoch', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss value', fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
